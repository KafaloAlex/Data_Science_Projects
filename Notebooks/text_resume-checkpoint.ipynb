{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7cc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "import cv2\n",
    "import pytesseract\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c45131",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98327ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARCELLE\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preparation du modele\n",
    "modele_name = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(modele_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(modele_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aabf104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraitement du texte\n",
    "def preprocess(texte):\n",
    "    texte_pretraiter = \"summarize : \" + texte\n",
    "    return texte_pretraiter\n",
    "\n",
    "\n",
    "# Extraction de texte de puis une image\n",
    "def extract_text_from_image(path):\n",
    "    image = Image.open(path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Extraction de texte a partir d'un fichier pdf\n",
    "def extract_text_from_pdf(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        texte = \"\"\n",
    "        for page in reader.pages:\n",
    "            texte += page.extract_text()\n",
    "        return texte\n",
    "    \n",
    "\n",
    "# Extraction de texte a partir d'une video\n",
    "def extract_text_from_video(file):\n",
    "    video = cv2.VideoCapture(file)\n",
    "    frames_interval = 30\n",
    "    frames_process = 0\n",
    "    texte_extrait = \"\"\n",
    "    \n",
    "    while video.isOpened():\n",
    "        success, frame = video.read()\n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        if frames_process % frames_interval == 0:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            texte = pytesseract.image_to_string(rgb)\n",
    "            texte_extrait += texte + '\\n'\n",
    "            \n",
    "        frames_process += 1\n",
    "        \n",
    "    video.release()\n",
    "    return texte_extrait\n",
    "\n",
    "# Generation du resume\n",
    "def resume_generation(texte):\n",
    "    texte_ = preprocess(texte)\n",
    "    tokenization = tokenizer.encode(texte_, return_tensors='pt', max_length=512, truncation=True)\n",
    "    sum_generation = model.generate(tokenization, num_beams=4, early_stopping=True, max_length=150)\n",
    "    summary = tokenizer.decode(sum_generation[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1ffa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c'est une histoire d'une guerre contre le pouvoir des riches qui est triste et drôle. un homme qui n'avait pas d'argent et qui ne pouvait presque pas se nourrir décida de créer une équipe contre les riches. il réunit plus de 1000 pauvres qui ne mangeaient pas à leur faim et commença à se battre pour de la nourriture.\n"
     ]
    }
   ],
   "source": [
    "pdf = 'texte.pdf'\n",
    "texte = extract_text_from_pdf(pdf)\n",
    "summary = resume_generation(texte)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc1c7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c'est une histoire d'une guerre contre le pouvoir des riches qui est triste et drdle. un homme qui n'avait pas d'argent et qui ne pouvait presque pas se nourrir décida de créer une équipe contre les riches. Pendant la nuit, les policiers beganrent leur chasse et ils les trouvérent a Lille. Ils les capturé pour les envoyer en esclavage.\n"
     ]
    }
   ],
   "source": [
    "image = \"C:\\\\Users\\\\MARCELLE\\\\Documents\\\\NLP PROJECT\\\\image.png\"\n",
    "texte_ = extract_text_from_image(image)\n",
    "summary_ = resume_generation(texte_)\n",
    "print(summary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1228efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je partais rendre visi — je partais rendre visite ama pet — je partais rendre visite ama petite amie et je me Suis arréte — je partais rendre visite ama petite amie et je me Suis arrété pour D — je partais rendre visite ama petite amie et je me Suis arrété pour pisser Il y aun vieux gui est des\n"
     ]
    }
   ],
   "source": [
    "video = \"C:\\\\Users\\\\MARCELLE\\\\Documents\\\\NLP PROJECT\\\\video.mp4\"\n",
    "texte_ = extract_text_from_video(video)\n",
    "summary_ = resume_generation(texte_)\n",
    "print(summary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e96adc",
   "metadata": {},
   "source": [
    "# Dash App Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ff382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed2cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting text_summary.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile text_summary.py\n",
    "\n",
    "import dash\n",
    "import PyPDF2\n",
    "import cv2\n",
    "import pytesseract\n",
    "import torch\n",
    "import base64\n",
    "import time\n",
    "\n",
    "from dash import html, dcc, State\n",
    "from dash.dependencies import Input, Output\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from PIL import Image\n",
    "from autocorrect import Speller\n",
    "\n",
    "external_scripts = [{\n",
    "    'src': 'https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js',\n",
    "    'integrity':\"sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM\",\n",
    "    'crossorigin': \"anonymous\"\n",
    "}]\n",
    "\n",
    "external_stylesheets = [{\n",
    "    'href': 'https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css',\n",
    "    'rel': 'stylesheet',\n",
    "    'integrity': 'sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC',\n",
    "    'crossorigin': 'anonymous'\n",
    "}]\n",
    "\n",
    "app = dash.Dash(__name__, suppress_callback_exceptions=True, external_scripts=external_scripts, \n",
    "                external_stylesheets=external_stylesheets)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Préparation du modèle et du tokenizer\n",
    "model_name = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Layout de l'application'\n",
    "\n",
    "app.layout = html.Div(\n",
    "    className='container border p-4 rounded justify-content-center mt-4',\n",
    "    style={\n",
    "        'background': '#f2f2f2'},\n",
    "    children=[\n",
    "        html.H1(\n",
    "            \"Extraction & Resume de texte\",\n",
    "            className='text-center fw-bold',\n",
    "#             style={'font-weight': 'bold', 'font-family': 'Arial', 'text-align': 'center'}\n",
    "        ),\n",
    "        html.Div(\n",
    "            className='row',\n",
    "#             style={'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Div(\n",
    "#                     style={'width': '45%'}\n",
    "                    className='col-md-6',\n",
    "                    children=[\n",
    "                        dcc.Upload(\n",
    "                            id='upload-data',\n",
    "                            children=html.Div([\n",
    "                                'Glissez et déposez ou ',\n",
    "                                html.A('sélectionnez un fichier image, video ou pdf')\n",
    "                            ], className='fst-italic'),\n",
    "                            style={\n",
    "                                'width': '100%',\n",
    "                                'height': '60px',\n",
    "                                'lineHeight': '60px',\n",
    "                                'borderWidth': '1px',\n",
    "                                'borderStyle': 'dashed',\n",
    "                                'borderRadius': '5px',\n",
    "                                'textAlign': 'center',\n",
    "                                'margin': '10px',\n",
    "                                'cursor': 'pointer',\n",
    "                            },\n",
    "                            multiple=False\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "               html.Div(\n",
    "                    children=[\n",
    "                        html.H4(\"Résumé\", className='fw-bold fst-italic'),\n",
    "                        dcc.Loading(\n",
    "                            id='loading-summary',\n",
    "                            type='default',\n",
    "                            children=[\n",
    "                                html.Div(id='output-summary', className='fs-5', style={'font-family': 'Verdana'})\n",
    "                            ]\n",
    "                        )\n",
    "                    ],\n",
    "                    className='col-md-6'\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Pretraitement du texte\n",
    "def preprocess(texte):\n",
    "    texte_pretraiter = \"summarize : \" + texte\n",
    "    return texte_pretraiter\n",
    "\n",
    "\n",
    "# Correction auto de texte\n",
    "def correction_texte(texte):\n",
    "    spell = Speller(lang='fr')\n",
    "    correction = spell(texte)\n",
    "    return correction\n",
    "\n",
    "\n",
    "# Extraction de texte de puis une image\n",
    "def extract_text_from_image(path):\n",
    "    image = Image.open(path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Extraction de texte a partir d'un fichier pdf\n",
    "def extract_text_from_pdf(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        texte = \"\"\n",
    "        for page in reader.pages:\n",
    "            texte += page.extract_text()\n",
    "        return texte\n",
    "    \n",
    "\n",
    "# Extraction de texte a partir d'une video\n",
    "def extract_text_from_video(file):\n",
    "    video = cv2.VideoCapture(file)\n",
    "    frames_interval = 30\n",
    "    frames_process = 0\n",
    "    texte_extrait = \"\"\n",
    "    \n",
    "    while video.isOpened():\n",
    "        success, frame = video.read()\n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        if frames_process % frames_interval == 0:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            texte = pytesseract.image_to_string(rgb)\n",
    "            texte_extrait += texte + '\\n'\n",
    "            \n",
    "        frames_process += 1\n",
    "        \n",
    "    video.release()\n",
    "    return texte_extrait\n",
    "\n",
    "\n",
    "# Generation du resume\n",
    "def resume_generation(texte):\n",
    "    texte_ = preprocess(texte)\n",
    "    tokenization = tokenizer.encode(texte_, return_tensors='pt', max_length=512, truncation=True)\n",
    "    sum_generation = model.generate(tokenization, num_beams=4, early_stopping=True, max_length=150)\n",
    "    summary = tokenizer.decode(sum_generation[0], skip_special_tokens=True)\n",
    "    resume = correction_texte(summary)\n",
    "    return resume\n",
    "\n",
    "\n",
    "def update_output(contents):\n",
    "    if contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "#         return content_type\n",
    "        if content_type.startswith('data:image/'):\n",
    "            # Extraction de texte à partir de l'image\n",
    "            image_data = content_string.split(';base64,')[-1]\n",
    "            with open('temp_image.png', 'wb') as file:\n",
    "                file.write(base64.b64decode(content_string))\n",
    "            text = extract_text_from_image('temp_image.png')\n",
    "            resume = resume_generation(text)\n",
    "        elif content_type.startswith('data:video/mp4'):\n",
    "            # Extraction de texte à partir de la vidéo\n",
    "            video_data = content_string.split(';base64,')[-1]\n",
    "            with open('temp_video.mp4', 'wb') as file:\n",
    "                file.write(base64.b64decode(content_string))\n",
    "            text = extract_text_from_video('temp_video.mp4')\n",
    "            resume = resume_generation(text)\n",
    "        elif content_type.startswith('data:application/pdf'):\n",
    "            # Extraction de texte à partir du fichier PDF\n",
    "            pdf_data = content_string.split(';base64,')[-1]\n",
    "            with open('temp_pdf.pdf', 'wb') as file:\n",
    "                file.write(base64.b64decode(content_string))\n",
    "            text = extract_text_from_pdf('temp_pdf.pdf')\n",
    "            resume = resume_generation(text)\n",
    "        else:\n",
    "            return \"Type de fichier non pris en charge.\"\n",
    "\n",
    "        return resume\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "# Callback pour la génération du résumé lors du chargement du fichier\n",
    "@app.callback(\n",
    "    Output('output-summary', 'children'),\n",
    "    [Input('upload-data', 'contents')],\n",
    "    [State('loading-summary', 'loading_state')]\n",
    ")\n",
    "\n",
    "\n",
    "def generate_summary(contents, loading_state):\n",
    "    if contents is not None:\n",
    "        return update_output(contents)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile app.py\n",
    "\n",
    "# import dash\n",
    "# import PyPDF2\n",
    "# import cv2\n",
    "# import pytesseract\n",
    "# import torch\n",
    "# import base64\n",
    "# import time\n",
    "# import io\n",
    "\n",
    "# from dash import html, dcc, State\n",
    "# from dash.dependencies import Input, Output\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "# from PIL import Image\n",
    "# from autocorrect import Speller\n",
    "# from pdf2image import convert_from_bytes\n",
    "\n",
    "\n",
    "# external_scripts = [{\n",
    "#     'src': 'https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js',\n",
    "#     'integrity':\"sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM\",\n",
    "#     'crossorigin': \"anonymous\"\n",
    "# }]\n",
    "\n",
    "# external_stylesheets = [{\n",
    "#     'href': 'https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css',\n",
    "#     'rel': 'stylesheet',\n",
    "#     'integrity': 'sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC',\n",
    "#     'crossorigin': 'anonymous'\n",
    "# }]\n",
    "\n",
    "# app = dash.Dash(__name__, suppress_callback_exceptions=True, external_scripts=external_scripts, \n",
    "#                 external_stylesheets=external_stylesheets)\n",
    "\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# # Préparation du modèle et du tokenizer\n",
    "# model_name = 't5-base'\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# # Layout de l'application'\n",
    "# app.layout = html.Div(\n",
    "#     className='container border p-4 rounded justify-content-center mt-4',\n",
    "#     style={\n",
    "#         'background': '#f2f2f2'},\n",
    "#     children=[\n",
    "#         html.H1(\n",
    "#             \"Extraction & Resume de texte\",\n",
    "#             className='text-center fw-bold',\n",
    "# #             style={'font-weight': 'bold', 'font-family': 'Arial', 'text-align': 'center'}\n",
    "#         ),\n",
    "#         html.Div(\n",
    "#             className='row',\n",
    "# #             style={'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "#             children=[\n",
    "#                 html.Div(\n",
    "#                     className='col-md-6',\n",
    "#                     children=[\n",
    "#                         dcc.Upload(\n",
    "#                             id='upload-data',\n",
    "#                             children=html.Div([\n",
    "#                                 'Glissez et déposez ou ',\n",
    "#                                 html.A('sélectionnez un fichier image, video ou pdf')\n",
    "#                             ], className='fst-italic'),\n",
    "#                             style={\n",
    "#                                 'width': '100%',\n",
    "#                                 'height': '60px',\n",
    "#                                 'lineHeight': '60px',\n",
    "#                                 'borderWidth': '1px',\n",
    "#                                 'borderStyle': 'dashed',\n",
    "#                                 'borderRadius': '5px',\n",
    "#                                 'textAlign': 'center',\n",
    "#                                 'margin': '10px',\n",
    "#                                 'cursor': 'pointer',\n",
    "#                             },\n",
    "#                             multiple=False\n",
    "#                         ),\n",
    "#                         html.Div(id='file-preview')\n",
    "#                     ]\n",
    "#                 ),\n",
    "#                 html.Div(\n",
    "#                     className='col-md-6',\n",
    "#                     children=[\n",
    "#                         html.H4(\"Résumé\", className='fw-bold fst-italic'),\n",
    "#                         dcc.Loading(\n",
    "#                             id='loading-summary',\n",
    "#                             type='default',\n",
    "#                             children=[\n",
    "#                                 html.Div(id='output-summary', className='fs-5', style={'font-family': 'Verdana'})\n",
    "#                             ]\n",
    "#                         )\n",
    "#                     ]\n",
    "#                 )\n",
    "#             ]\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# # Pretraitement du texte\n",
    "# def preprocess(texte):\n",
    "#     texte_pretraiter = \"Give me a precise and clear summary of this text : \" + texte\n",
    "#     return texte_pretraiter\n",
    "\n",
    "\n",
    "# # Correction auto de texte\n",
    "# def correction_texte(texte):\n",
    "#     spell = Speller(lang='fr')\n",
    "#     correction = spell(texte)\n",
    "#     return correction\n",
    "\n",
    "\n",
    "# # Extraction de texte de puis une image\n",
    "# def extract_text_from_image(path):\n",
    "#     image = Image.open(path)\n",
    "#     text = pytesseract.image_to_string(image)\n",
    "#     return text\n",
    "\n",
    "\n",
    "# # Extraction de texte a partir d'un fichier pdf\n",
    "# def extract_text_from_pdf(file):\n",
    "#     with open(file, 'rb') as f:\n",
    "#         reader = PyPDF2.PdfReader(file)\n",
    "#         texte = \"\"\n",
    "#         for page in reader.pages:\n",
    "#             texte += page.extract_text()\n",
    "#         return texte\n",
    "    \n",
    "\n",
    "# # Extraction de texte a partir d'une video\n",
    "# def extract_text_from_video(file):\n",
    "#     video = cv2.VideoCapture(file)\n",
    "#     frames_interval = 30\n",
    "#     frames_process = 0\n",
    "#     texte_extrait = \"\"\n",
    "    \n",
    "#     while video.isOpened():\n",
    "#         success, frame = video.read()\n",
    "        \n",
    "#         if not success:\n",
    "#             break\n",
    "            \n",
    "#         if frames_process % frames_interval == 0:\n",
    "#             rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             texte = pytesseract.image_to_string(rgb)\n",
    "#             texte_extrait += texte + '\\n'\n",
    "            \n",
    "#         frames_process += 1\n",
    "        \n",
    "#     video.release()\n",
    "#     return texte_extrait\n",
    "\n",
    "\n",
    "# # Generation du resume\n",
    "# def resume_generation(texte):\n",
    "#     texte_ = preprocess(texte)\n",
    "#     tokenization = tokenizer.encode(texte_, return_tensors='pt', max_length=512, truncation=True)\n",
    "#     sum_generation = model.generate(tokenization, num_beams=4, early_stopping=True, max_length=150)\n",
    "#     summary = tokenizer.decode(sum_generation[0], skip_special_tokens=True)\n",
    "#     resume = correction_texte(summary)\n",
    "#     return resume\n",
    "\n",
    "\n",
    "# def update_output(contents):\n",
    "#     if contents is not None:\n",
    "#         content_type, content_string = contents.split(',')\n",
    "# #         return content_type\n",
    "#         if content_type.startswith('data:image/'):\n",
    "#             # Extraction de texte à partir de l'image\n",
    "#             image_data = content_string.split(';base64,')[-1]\n",
    "#             with open('temp_image.png', 'wb') as file:\n",
    "#                 file.write(base64.b64decode(content_string))\n",
    "#             text = extract_text_from_image('temp_image.png')\n",
    "#             resume = resume_generation(text)\n",
    "#         elif content_type.startswith('data:video/mp4'):\n",
    "#             # Extraction de texte à partir de la vidéo\n",
    "#             video_data = content_string.split(';base64,')[-1]\n",
    "#             with open('temp_video.mp4', 'wb') as file:\n",
    "#                 file.write(base64.b64decode(content_string))\n",
    "#             text = extract_text_from_video('temp_video.mp4')\n",
    "#             resume = resume_generation(text)\n",
    "#         elif content_type.startswith('data:application/pdf'):\n",
    "#             # Extraction de texte à partir du fichier PDF\n",
    "#             pdf_data = content_string.split(';base64,')[-1]\n",
    "#             with open('temp_pdf.pdf', 'wb') as file:\n",
    "#                 file.write(base64.b64decode(content_string))\n",
    "#             text = extract_text_from_pdf('temp_pdf.pdf')\n",
    "#             resume = resume_generation(text)\n",
    "#         else:\n",
    "#             return \"Type de fichier non pris en charge.\"\n",
    "\n",
    "#         return resume\n",
    "\n",
    "#     return \"\"\n",
    "\n",
    "\n",
    "# def image_url(img):\n",
    "#     with io.BytesIO() as buffer:\n",
    "#         img.save(buffer, 'PNG')\n",
    "#         img_str = base64.b64encode(buffer.getvalue()).decode()\n",
    "#         return f'data:image/png;base64,{img_str}'\n",
    "\n",
    "\n",
    "# def parse_contents(contents, filename):\n",
    "#     content_type, content_string = contents.split(',')\n",
    "#     decoded = base64.b64decode(content_string)\n",
    "    \n",
    "#     if 'image' in content_type:\n",
    "#         image = base64.b64encode(decoded).decode('utf-8')\n",
    "#         return html.Div([\n",
    "#             html.H5(filename),\n",
    "#             html.Img(src='data:image/png;base64,' + image, style={'width': '100%'})\n",
    "#         ])\n",
    "#     elif 'pdf' in content_type:\n",
    "#         pdf = io.BytesIO(decoded)\n",
    "#         images = convert_from_bytes(pdf.read())\n",
    "#         return html.Div([\n",
    "#             html.H5(filename),\n",
    "#             *[html.Img(src=image_url(img), style={'width': '100%'}) for img in images]\n",
    "#         ])\n",
    "\n",
    "\n",
    "\n",
    "# # Callback pour la génération du résumé lors du chargement du fichier\n",
    "# @app.callback(\n",
    "#     Output('output-summary', 'children'),\n",
    "#     [Input('upload-data', 'contents')],\n",
    "#     [State('upload-data', 'filename'),\n",
    "#      State('loading-summary', 'loading_state')]\n",
    "# )\n",
    "# def update_file_preview(contents, filename, loading_state):\n",
    "#     if contents is not None:\n",
    "#         file_preview = parse_contents(contents, filename)\n",
    "#         return file_preview\n",
    "    \n",
    "\n",
    "# def generate_summary(contents, loading_state):\n",
    "#     if contents is not None:\n",
    "#         return update_output(contents)\n",
    "#     else:\n",
    "#         return ''\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run_server(debug=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
